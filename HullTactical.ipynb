{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b3035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 0. Import libraries & Setup\n",
    "# ============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(42)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---- å…¨å±€å‚æ•° ----\n",
    "TEST_DAYS = 180\n",
    "MIN_INVESTMENT = 0\n",
    "MAX_INVESTMENT = 2\n",
    "TARGET_VOL = 0.23\n",
    "\n",
    "# [æ ¸å¿ƒè¯„åˆ†å·¥å…·]\n",
    "def calc_official_metric(strat_ret, mkt_ret, rf, trading_days=252):\n",
    "    strat_ret = np.nan_to_num(np.array(strat_ret))\n",
    "    mkt_ret = np.nan_to_num(np.array(mkt_ret))\n",
    "    rf = np.nan_to_num(np.array(rf))\n",
    "    strat_excess = strat_ret - rf\n",
    "    strat_mean = np.mean(strat_excess)\n",
    "    strat_std = np.std(strat_ret)\n",
    "    if strat_std == 0: return 0.0\n",
    "    sharpe = (strat_mean / strat_std) * np.sqrt(trading_days)\n",
    "    strat_vol = strat_std * np.sqrt(trading_days) * 100\n",
    "    mkt_excess = mkt_ret - rf\n",
    "    mkt_mean = np.mean(mkt_excess)\n",
    "    mkt_std = np.std(mkt_ret)\n",
    "    mkt_vol = mkt_std * np.sqrt(trading_days) * 100\n",
    "    if mkt_vol == 0: excess_vol = 0\n",
    "    else: excess_vol = max(0, strat_vol / mkt_vol - 1.2)\n",
    "    vol_penalty = 1 + excess_vol\n",
    "    ann_strat_mean = strat_mean * trading_days * 100\n",
    "    ann_mkt_mean = mkt_mean * trading_days * 100\n",
    "    return_gap = max(0, ann_mkt_mean - ann_strat_mean)\n",
    "    return_penalty = 1 + (return_gap**2) / 100\n",
    "    return sharpe / (vol_penalty * return_penalty)\n",
    "\n",
    "# ============================================\n",
    "# 1. æ•°æ®åŠ è½½ä¸ç‰¹å¾å·¥ç¨‹\n",
    "# ============================================\n",
    "print(\"Step 1: Loading & Generating Features...\")\n",
    "train_all = pd.read_csv('/kaggle/input/hull-tactical-market-prediction/train.csv')\n",
    "train_all = train_all.sort_values('date_id').reset_index(drop=True)\n",
    "train_all['past_returns'] = train_all['forward_returns'].shift(1).fillna(0)\n",
    "\n",
    "lags = [1, 2, 3, 5, 10, 21, 63]\n",
    "for lag in lags:\n",
    "    train_all[f'ret_lag_{lag}'] = train_all['past_returns'].shift(lag).fillna(0)\n",
    "\n",
    "train_all['vol_20'] = train_all['past_returns'].rolling(20).std().fillna(0)\n",
    "train_all['vol_60'] = train_all['past_returns'].rolling(60).std().fillna(0)\n",
    "train_all['skew_60'] = train_all['past_returns'].rolling(60).skew().fillna(0)\n",
    "train_all['mom_20'] = train_all['past_returns'].rolling(20).sum().fillna(0)\n",
    "train_all['mom_60'] = train_all['past_returns'].rolling(60).sum().fillna(0)\n",
    "train_all['mom_ratio'] = train_all['mom_20'] / (train_all['mom_60'].abs() + 1e-9)\n",
    "train_all['vol_ratio'] = train_all['vol_20'] / (train_all['vol_60'] + 1e-9)\n",
    "train_all['ret_vol_int'] = train_all['past_returns'] * train_all['vol_20']\n",
    "\n",
    "safe_price = (1 + train_all['past_returns']).cumprod()\n",
    "def rsi_wilder_safe(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.ewm(alpha=1/period, min_periods=period).mean()\n",
    "    avg_loss = loss.ewm(alpha=1/period, min_periods=period).mean()\n",
    "    rs = avg_gain / (avg_loss + 1e-12)\n",
    "    return 100 - 100 / (1 + rs)\n",
    "train_all['rsi'] = rsi_wilder_safe(safe_price).fillna(50)\n",
    "\n",
    "train_all['ma_long'] = train_all['past_returns'].rolling(window=200).mean().fillna(0)\n",
    "train_all['ma_short'] = train_all['past_returns'].rolling(window=10).mean().fillna(0)\n",
    "train_all['trend_mask'] = np.where(train_all['ma_short'] < train_all['ma_long'], 0.95, 1.0)\n",
    "\n",
    "vol_200 = train_all['past_returns'].rolling(window=200).std()\n",
    "vol_60 = train_all['past_returns'].rolling(window=60).std()\n",
    "train_all['long_vol'] = np.sqrt(0.7 * vol_200**2 + 0.3 * vol_60**2).fillna(method='ffill').fillna(0.01)\n",
    "\n",
    "# ============================================\n",
    "# 2. æ•°æ®åˆ‡åˆ†\n",
    "# ============================================\n",
    "print(\"Step 2: Splitting & Preprocessing...\")\n",
    "meta_cols = ['date_id', 'forward_returns', 'risk_free_rate',\n",
    "             'market_forward_excess_returns', 'trend_mask', 'long_vol', 'vol_20']\n",
    "feature_cols = [c for c in train_all.columns if c not in meta_cols\n",
    "                and c not in ['ma_long', 'ma_short', 'past_returns', 'mom_20', 'mom_60']]\n",
    "\n",
    "sim_test = train_all.iloc[-TEST_DAYS:].copy().reset_index(drop=True)\n",
    "train = train_all.iloc[:-TEST_DAYS].copy().reset_index(drop=True)\n",
    "\n",
    "X_train_raw = train[feature_cols].ffill().fillna(0)\n",
    "X_test_raw = sim_test[feature_cols].ffill().fillna(0)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_raw)\n",
    "X_test_scaled = scaler.transform(X_test_raw)\n",
    "\n",
    "if 'market_forward_excess_returns' in train.columns:\n",
    "    y_train = train['market_forward_excess_returns']\n",
    "else:\n",
    "    y_train = train['forward_returns']\n",
    "y_train_class = (y_train > 0).astype(int)\n",
    "\n",
    "# ============================================\n",
    "# 2.5 å®šä¹‰ç¥ç»ç½‘ç»œç±»\n",
    "# ============================================\n",
    "print(\"Step 2.5: Defining Neural Network Classes...\")\n",
    "\n",
    "class SharpeLoss(nn.Module):\n",
    "    def __init__(self, ann_factor=252):\n",
    "        super(SharpeLoss, self).__init__()\n",
    "        self.ann_factor = ann_factor\n",
    "    def forward(self, output, target_returns):\n",
    "        strategy_returns = output * target_returns\n",
    "        mean_ret = torch.mean(strategy_returns)\n",
    "        std_ret = torch.std(strategy_returns) + 1e-6\n",
    "        sharpe = (mean_ret / std_ret) * torch.sqrt(torch.tensor(self.ann_factor))\n",
    "        return -sharpe\n",
    "\n",
    "class SharpeMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256, dropout=0.3):\n",
    "        super(SharpeMLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "# ============================================\n",
    "# 3. Walk-Forward OOF ç”Ÿæˆ\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"â³ STARTING WALK-FORWARD VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "TEST_WINDOW = 180\n",
    "INITIAL_TRAIN_YEARS = 5\n",
    "MIN_TRAIN_DAYS = 252 * INITIAL_TRAIN_YEARS\n",
    "\n",
    "oof_pred_ridge = np.full(len(train), np.nan)\n",
    "oof_pred_nn = np.full(len(train), np.nan)\n",
    "oof_pred_prob = np.full(len(train), np.nan)\n",
    "\n",
    "X_full_raw = train[feature_cols].replace([np.inf, -np.inf], 0).ffill().fillna(0).values\n",
    "y_full_target = train['market_forward_excess_returns'].values\n",
    "y_full_raw = train['forward_returns'].values\n",
    "y_full_cls = (y_full_target > 0).astype(int)\n",
    "\n",
    "splits = range(MIN_TRAIN_DAYS, len(train), TEST_WINDOW)\n",
    "print(f\"ğŸ”„ Total Folds to Run: {len(splits)}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for i, split_idx in enumerate(tqdm(splits)):\n",
    "    train_end = split_idx\n",
    "    test_end = min(split_idx + TEST_WINDOW, len(train))\n",
    "    if train_end >= len(train): break\n",
    "\n",
    "    X_tr = X_full_raw[:train_end]\n",
    "    y_tr_r = y_full_target[:train_end]\n",
    "    y_tr_n = y_full_raw[:train_end]\n",
    "    y_tr_c = y_full_cls[:train_end]\n",
    "    X_te = X_full_raw[train_end:test_end]\n",
    "\n",
    "    scaler_iter = RobustScaler()\n",
    "    X_tr_sc = scaler_iter.fit_transform(X_tr)\n",
    "    X_te_sc = scaler_iter.transform(X_te)\n",
    "\n",
    "    # 1. Ridge\n",
    "    model_r = Ridge(alpha=100)\n",
    "    model_r.fit(X_tr_sc, y_tr_r)\n",
    "    oof_pred_ridge[train_end:test_end] = model_r.predict(X_te_sc)\n",
    "\n",
    "    # 2. LGBM\n",
    "    model_l = lgb.LGBMClassifier(n_estimators=60, learning_rate=0.05, verbose=-1, random_state=42, n_jobs=1)\n",
    "    model_l.fit(X_tr_sc, y_tr_c)\n",
    "    oof_pred_prob[train_end:test_end] = model_l.predict_proba(X_te_sc)[:, 1]\n",
    "\n",
    "    # 3. NN\n",
    "    temp_model = SharpeMLP(input_dim=X_tr.shape[1]).to(device)\n",
    "    optimizer = optim.Adam(temp_model.parameters(), lr=0.001)\n",
    "    criterion = SharpeLoss()\n",
    "    t_X_tr = torch.tensor(X_tr_sc, dtype=torch.float32).to(device)\n",
    "    t_y_tr = torch.tensor(y_tr_n.reshape(-1,1), dtype=torch.float32).to(device)\n",
    "\n",
    "    temp_model.train()\n",
    "    for epoch in range(12):\n",
    "        optimizer.zero_grad()\n",
    "        out = temp_model(t_X_tr)\n",
    "        loss = criterion(out, t_y_tr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    temp_model.eval()\n",
    "    with torch.no_grad():\n",
    "        t_X_te = torch.tensor(X_te_sc, dtype=torch.float32).to(device)\n",
    "        pred_n = temp_model(t_X_te).cpu().numpy().flatten()\n",
    "    oof_pred_nn[train_end:test_end] = pred_n\n",
    "\n",
    "print(\"âœ… Walk-Forward Generation Complete.\")\n",
    "\n",
    "# ============================================\n",
    "# Step 5: Monte Carlo Robust Optimization\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ§¬ STEP 5: ROBUST PARAMETER SEARCH (MONTE CARLO + CVaR)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# --- 1. å‡†å¤‡æœ‰æ•ˆæ•°æ® ---\n",
    "valid_mask = ~np.isnan(oof_pred_ridge)\n",
    "# é¢„æµ‹å€¼\n",
    "v_ridge = oof_pred_ridge[valid_mask]\n",
    "v_nn = oof_pred_nn[valid_mask]\n",
    "v_prob = oof_pred_prob[valid_mask]\n",
    "# å¸‚åœºæ•°æ®\n",
    "v_vol20 = train['vol_20'].values[valid_mask]\n",
    "v_long = train['long_vol'].values[valid_mask]\n",
    "v_trend = train['trend_mask'].values[valid_mask]\n",
    "v_ret = train['forward_returns'].values[valid_mask]\n",
    "v_rf = train['risk_free_rate'].values[valid_mask]\n",
    "v_mkt = train['forward_returns'].values[valid_mask]\n",
    "\n",
    "# æ ‡å‡†åŒ– (OOF Stats)\n",
    "R_MEAN, R_STD = np.mean(v_ridge), np.std(v_ridge)\n",
    "N_MEAN, N_STD = np.mean(v_nn), np.std(v_nn)\n",
    "rank_ridge = np.clip((v_ridge - R_MEAN) / (R_STD + 1e-9), -3, 3) / 3.0\n",
    "rank_nn = np.clip((v_nn - N_MEAN) / (N_STD + 1e-9), -3, 3) / 3.0\n",
    "confidence = np.abs((v_prob**2) - ((1-v_prob)**2))\n",
    "\n",
    "# --- 2. é¢„ç”Ÿæˆ 1000 ä¸ªå¹³è¡Œå®‡å®™ ---\n",
    "N_SIMS = 1000\n",
    "SLICE_LEN = 180\n",
    "max_idx = len(v_ret) - SLICE_LEN\n",
    "\n",
    "np.random.seed(42)\n",
    "start_idxs = np.random.randint(0, max_idx, N_SIMS)\n",
    "indices = start_idxs[:, None] + np.arange(SLICE_LEN)\n",
    "\n",
    "# é¢„åˆ‡ç‰‡\n",
    "mc_vol20 = v_vol20[indices]\n",
    "mc_long = v_long[indices]\n",
    "mc_trend = v_trend[indices]\n",
    "mc_ret = v_ret[indices]\n",
    "mc_rf = v_rf[indices]\n",
    "mc_mkt = v_mkt[indices]\n",
    "# ä¿¡å·æ•°æ®\n",
    "mc_ridge = rank_ridge[indices]\n",
    "mc_nn = rank_nn[indices]\n",
    "mc_conf = confidence[indices]\n",
    "\n",
    "# é¢„è®¡ç®—å›ºå®šæ æ†éƒ¨åˆ†\n",
    "mc_alpha_scale = np.clip(TARGET_VOL / (mc_vol20 * np.sqrt(252) + 1e-6), 0.7, 1.3)\n",
    "mc_raw_lev = TARGET_VOL / (mc_long * np.sqrt(252) + 1e-6)\n",
    "mc_port_lev = np.clip(mc_raw_lev, 0.8, 1.25)\n",
    "mc_combined_lev = mc_alpha_scale * mc_port_lev * mc_trend\n",
    "\n",
    "# --- 3. å‘é‡åŒ–è¯„åˆ†å‡½æ•° ---\n",
    "def vectorized_hull_score(strat_ret_matrix, mkt_ret_matrix, rf_matrix):\n",
    "    # ç­–ç•¥æŒ‡æ ‡\n",
    "    excess = strat_ret_matrix - rf_matrix\n",
    "    mean_exc = np.mean(excess, axis=1)\n",
    "    std_strat = np.std(strat_ret_matrix, axis=1) + 1e-9\n",
    "\n",
    "    sharpe = (mean_exc / std_strat) * np.sqrt(252)\n",
    "    vol_strat = std_strat * np.sqrt(252) * 100\n",
    "\n",
    "    # å¸‚åœºæŒ‡æ ‡\n",
    "    mkt_exc = mkt_ret_matrix - rf_matrix\n",
    "    mean_mkt = np.mean(mkt_exc, axis=1)\n",
    "    std_mkt = np.std(mkt_ret_matrix, axis=1) + 1e-9\n",
    "    vol_mkt = std_mkt * np.sqrt(252) * 100\n",
    "\n",
    "    # ç½šåˆ†\n",
    "    ratio = vol_strat / (vol_mkt + 1e-9)\n",
    "    exc_vol = np.maximum(0, ratio - 1.2)\n",
    "    exc_vol = np.where(vol_mkt < 1e-4, 0, exc_vol)\n",
    "    vol_pen = 1 + exc_vol\n",
    "\n",
    "    ann_ret_strat = mean_exc * 252 * 100\n",
    "    ann_ret_mkt = mean_mkt * 252 * 100\n",
    "    gap = np.maximum(0, ann_ret_mkt - ann_ret_strat)\n",
    "    ret_pen = 1 + (gap**2) / 100\n",
    "\n",
    "    return sharpe / (vol_pen * ret_pen)\n",
    "\n",
    "# --- 4. æš´åŠ›ç½‘æ ¼æœç´¢ (å« ES/CVaR) ---\n",
    "best_robust_score = -999\n",
    "final_w = 0.5\n",
    "final_m = 1.0\n",
    "\n",
    "print(f\"ğŸš€ Simulating {N_SIMS} universes per parameter set...\")\n",
    "# æ‰“å°è¡¨å¤´å¢åŠ  ES_05 (Expected Shortfall 5%)\n",
    "print(f\"{'Ridge_W':<8} {'Mult_M':<8} | {'Mean':<8} {'VaR_5%':<8} {'ES_5%':<8} {'Win%':<6} | {'Score'}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for w in np.arange(0.0, 1.01, 0.2):\n",
    "    mc_hybrid = (w * mc_ridge + (1-w) * mc_nn) * mc_conf\n",
    "\n",
    "    for m in np.arange(0.5, 3.0, 0.25):\n",
    "        # è®¡ç®—ä»“ä½\n",
    "        base_alloc = mc_port_lev * mc_trend\n",
    "        active_alloc = mc_hybrid * m * mc_combined_lev\n",
    "        alloc = np.clip(base_alloc + active_alloc, MIN_INVESTMENT, MAX_INVESTMENT)\n",
    "\n",
    "        # è®¡ç®—æ”¶ç›Šä¸åˆ†æ•°\n",
    "        strat_ret = mc_rf * (1 - alloc) + alloc * mc_ret\n",
    "        scores = vectorized_hull_score(strat_ret, mc_mkt, mc_rf)\n",
    "\n",
    "        # --- ç»Ÿè®¡æŒ‡æ ‡æ ¸å¿ƒ ---\n",
    "        mean_s = np.mean(scores)\n",
    "\n",
    "        # 1. è®¡ç®— 5% åˆ†ä½æ•° (VaR)\n",
    "        percentile_05 = np.percentile(scores, 5)\n",
    "\n",
    "        # 2. è®¡ç®— 5% ä»¥ä¸‹çš„å‡å€¼ (Expected Shortfall / CVaR)\n",
    "        # é€»è¾‘ï¼šæ‰¾å‡ºæ‰€æœ‰å°äºç­‰äº 5% åˆ†ä½æ•°çš„åˆ†æ•°ï¼Œæ±‚å¹³å‡\n",
    "        tail_scores = scores[scores <= percentile_05]\n",
    "        worst_05_mean = np.mean(tail_scores) if len(tail_scores) > 0 else percentile_05\n",
    "\n",
    "        win_r = np.mean(scores > 0)\n",
    "\n",
    "        # --- ç¨³å¥æ€§æ‰“åˆ†è§„åˆ™ ---\n",
    "        # è§„åˆ™å‡çº§ï¼šå¦‚æœ 5% å°¾éƒ¨å‡å€¼å¤ªå·®ï¼Œç›´æ¥æ¯™æ‰\n",
    "        # è¿™æ¯”åªçœ‹ VaR æ›´å®‰å…¨ï¼Œé˜²æ­¢â€œé»‘å¤©é¹…â€\n",
    "\n",
    "        if worst_05_mean < -2.0: # å¦‚æœå°¾éƒ¨å‡å€¼ä½äº -2.0ï¼Œè¯´æ˜ä¸€æ—¦å‡ºäº‹å°±æ˜¯å¤§äº‹\n",
    "            robust_metric = -99\n",
    "        elif percentile_05 < -1.5: # ä¼ ç»Ÿçš„ VaR æ£€æŸ¥\n",
    "            robust_metric = -50\n",
    "        else:\n",
    "            robust_metric = mean_s\n",
    "\n",
    "        if m % 1.0 == 0:\n",
    "             print(f\"{w:<8.1f} {m:<8.2f} | {mean_s:<8.4f} {percentile_05:<8.4f} {worst_05_mean:<8.4f} {win_r:<6.2%} | {robust_metric:.4f}\")\n",
    "\n",
    "        if robust_metric > best_robust_score:\n",
    "            best_robust_score = robust_metric\n",
    "            final_w = w\n",
    "            final_m = m\n",
    "\n",
    "print(\"-\" * 75)\n",
    "print(f\"ğŸ† Best Robust Parameters (Optimized for Tail Risk):\")\n",
    "print(f\"âœ… Optimal Ridge Weight: {final_w:.2f}\")\n",
    "print(f\"âœ… Optimal Multiplier:   {final_m:.2f}\")\n",
    "print(f\"ğŸ“Š Robust Metric Score:  {best_robust_score:.4f}\")\n",
    "\n",
    "# è‡ªåŠ¨å®‰å…¨ä¿®æ­£ (åŸºäº ES é€»è¾‘)\n",
    "if final_m > 2.2:\n",
    "    print(\"\\nâš ï¸ è‡ªåŠ¨å®‰å…¨ä¿®æ­£: é™ä½æ æ†ä»¥æ„å»ºå®‰å…¨ç¼“å†²\")\n",
    "    final_m = min(final_m, 2.2)\n",
    "    print(f\"ğŸ”’ Final Safe Multiplier: {final_m}\")\n",
    "\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# ============================================\n",
    "# [é‡è¦] 6. æœ€ç»ˆè®­ç»ƒä¸é¢„æµ‹ (Step 6)\n",
    "# ============================================\n",
    "print(\"\\nStep 6: Final Prediction on Test Set...\")\n",
    "\n",
    "# ============================================\n",
    "# ç¼ºå¤±çš„å‡½æ•°å®šä¹‰ï¼šlocal_score_check\n",
    "# ============================================\n",
    "def local_score_check(sol, sub):\n",
    "    \"\"\"\n",
    "    åœ¨æµ‹è¯•é›†ä¸Šè®¡ç®—æœ€ç»ˆçš„å®˜æ–¹åˆ†æ•°\n",
    "    \"\"\"\n",
    "    sol = sol.copy().reset_index(drop=True)\n",
    "    sub = sub.copy().reset_index(drop=True)\n",
    "    sol['position'] = sub['prediction']\n",
    "\n",
    "    # ç­–ç•¥å‡€å€¼è®¡ç®—\n",
    "    sol['strategy_returns'] = sol['risk_free_rate'] * (1 - sol['position']) + sol['position'] * sol['forward_returns']\n",
    "\n",
    "    # è°ƒç”¨å®˜æ–¹è¯„åˆ†å‡½æ•° (éœ€ç¡®ä¿ calc_official_metric å·²å®šä¹‰)\n",
    "    score = calc_official_metric(\n",
    "        strat_ret=sol['strategy_returns'],\n",
    "        mkt_ret=sol['forward_returns'],\n",
    "        rf=sol['risk_free_rate']\n",
    "    )\n",
    "\n",
    "    # è¾…åŠ©æŒ‡æ ‡æ‰“å°\n",
    "    strat_std = sol['strategy_returns'].std()\n",
    "    market_std = sol['forward_returns'].std()\n",
    "    strat_vol = strat_std * np.sqrt(252) * 100\n",
    "    market_vol = market_std * np.sqrt(252) * 100\n",
    "    vol_penalty = 1 + max(0, strat_vol / market_vol - 1.2)\n",
    "\n",
    "    print(f\"\\n--- ğŸ Final Performance Report ---\")\n",
    "    print(f\"Strategy Vol: {strat_vol:.2f}% (Market: {market_vol:.2f}%)\")\n",
    "    print(f\"Vol Penalty:  {vol_penalty:.4f}\")\n",
    "    return score\n",
    "\n",
    "# 1. å…¨é‡è®­ç»ƒ Ridge\n",
    "model_ridge = Ridge(alpha=100)\n",
    "model_ridge.fit(X_train_scaled, y_train)\n",
    "pred_r_test = model_ridge.predict(X_test_scaled)\n",
    "\n",
    "# 2. å…¨é‡è®­ç»ƒ LGBM\n",
    "model_clf = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.05, verbose=-1, random_state=42)\n",
    "model_clf.fit(X_train_scaled, y_train_class)\n",
    "pred_p_test = model_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 3. å…¨é‡è®­ç»ƒ NN\n",
    "# å®šä¹‰å¤–éƒ¨è®­ç»ƒå‡½æ•°\n",
    "def train_nn_final(X, y, epochs=25):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SharpeMLP(input_dim=X.shape[1]).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    criterion = SharpeLoss()\n",
    "    t_X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    t_y = torch.tensor(y.values.reshape(-1,1), dtype=torch.float32).to(device)\n",
    "    model.train()\n",
    "    for e in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(t_X)\n",
    "        loss = criterion(out, t_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model, device\n",
    "\n",
    "y_train_raw = train['forward_returns']\n",
    "model_nn_final, device = train_nn_final(X_train_scaled, y_train_raw)\n",
    "\n",
    "t_X_test = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "with torch.no_grad():\n",
    "    pred_n_test = model_nn_final(t_X_test).cpu().numpy().flatten()\n",
    "\n",
    "# 4. æ··åˆä¸ç”Ÿæˆç»“æœ\n",
    "z_r = np.clip((pred_r_test - R_MEAN) / (R_STD + 1e-9), -3, 3) / 3.0\n",
    "z_n = np.clip((pred_n_test - N_MEAN) / (N_STD + 1e-9), -3, 3) / 3.0\n",
    "conf = np.abs((pred_p_test**2) - ((1-pred_p_test)**2))\n",
    "\n",
    "y_final = (final_w * z_r + (1-final_w) * z_n) * conf\n",
    "\n",
    "curr_vol = sim_test['vol_20'].ffill().fillna(0.01).values\n",
    "alpha_s = np.clip(TARGET_VOL / (curr_vol * np.sqrt(252) + 1e-6), 0.7, 1.3)\n",
    "curr_long = sim_test['long_vol'].values\n",
    "port_l = np.clip(TARGET_VOL / (curr_long * np.sqrt(252) + 1e-6), 0.8, 1.25)\n",
    "trend = sim_test['trend_mask'].values\n",
    "\n",
    "alloc_final = np.clip((1.0 + y_final * final_m * alpha_s) * port_l * trend, MIN_INVESTMENT, MAX_INVESTMENT)\n",
    "\n",
    "submission = pd.DataFrame({'date_id': sim_test['date_id'], 'prediction': alloc_final})\n",
    "\n",
    "# ============================================\n",
    "# 7. è¯„åˆ†æ£€æŸ¥\n",
    "# ============================================\n",
    "final_score = local_score_check(sim_test, submission)\n",
    "print(f\"âœ… Final Test Score: {final_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
